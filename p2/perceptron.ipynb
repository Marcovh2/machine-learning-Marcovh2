{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Schrijf een klasse Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self, name, weights, bias):\n",
    "        self.name = name\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.accum_loss = 0\n",
    "        self.training_iterations = 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Perceptron '{self.name}' with input weights {self.weights} and bias {self.bias}.\"\n",
    "    \n",
    "    def output(self, input):\n",
    "        if type(input) == int:\n",
    "            input = [input]\n",
    "        if len(input) != len(self.weights):\n",
    "            raise ValueError(\"The number of inputs must be equal to the number of weights.\")\n",
    "        total = 0\n",
    "        for i in range(len(input)):\n",
    "            total += input[i] * self.weights[i]\n",
    "        return int(total + self.bias >= 0)\n",
    "    \n",
    "    def update(self, learning_rate, input, desired):\n",
    "        output = self.output(input)\n",
    "        error = desired - output\n",
    "        self.bias += learning_rate * error\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += learning_rate * error * input[i]\n",
    "        self.accum_loss += error**2\n",
    "        self.training_iterations += 1\n",
    "\n",
    "    def loss(self):\n",
    "        try:\n",
    "            return self.accum_loss / self.training_iterations\n",
    "        except ZeroDivisionError:\n",
    "            return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test je Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Initialiseer een Perceptron voor elk van de INVERT-, AND- en OR-poorten en test of ze op de juiste manier werken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "onebit_binary_combinations = (0, 1)\n",
    "twobit_binary_combinations = ((0, 0), (0, 1), (1, 0), (1, 1))\n",
    "threebit_binary_combinations = ((0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INVERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'NOT' with input weights [-1] and bias 0.\n",
      "NOT 0 = 1\n",
      "NOT 1 = 0\n"
     ]
    }
   ],
   "source": [
    "p_inv = Perceptron(\"NOT\", [-1], 0)\n",
    "print(p_inv)\n",
    "\n",
    "for input in onebit_binary_combinations:\n",
    "    print(f\"NOT {input} = {p_inv.output(input)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'AND' with input weights [1, 1] and bias -2.\n",
      "Input: (0, 0), Output: 0\n",
      "Input: (0, 1), Output: 0\n",
      "Input: (1, 0), Output: 0\n",
      "Input: (1, 1), Output: 1\n"
     ]
    }
   ],
   "source": [
    "p_and = Perceptron(\"AND\", [1, 1], -2)\n",
    "print(p_and)\n",
    "\n",
    "for i in twobit_binary_combinations:\n",
    "    print(f\"Input: {i}, Output: {p_and.output(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'OR' with input weights [1, 1] and bias -1.\n",
      "Input: (0, 0), Output: 0\n",
      "Input: (0, 1), Output: 1\n",
      "Input: (1, 0), Output: 1\n",
      "Input: (1, 1), Output: 1\n"
     ]
    }
   ],
   "source": [
    "p_or = Perceptron(\"OR\", [1, 1], -1)\n",
    "print(p_or)\n",
    "\n",
    "for i in twobit_binary_combinations:\n",
    "    print(f\"Input: {i}, Output: {p_or.output(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Initialiseer een Perceptron voor een NOR-poort met drie ingangen en test of deze op de juiste manier werkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'NOR' with input weights [-1, -1, -1] and bias 0.\n",
      "Input: (0, 0, 0), Output: 1\n",
      "Input: (0, 0, 1), Output: 0\n",
      "Input: (0, 1, 0), Output: 0\n",
      "Input: (0, 1, 1), Output: 0\n",
      "Input: (1, 0, 0), Output: 0\n",
      "Input: (1, 0, 1), Output: 0\n",
      "Input: (1, 1, 0), Output: 0\n",
      "Input: (1, 1, 1), Output: 0\n"
     ]
    }
   ],
   "source": [
    "p_nor = Perceptron(\"NOR\", [-1, -1, -1], 0)\n",
    "print(p_nor)\n",
    "\n",
    "for i in threebit_binary_combinations:\n",
    "    print(f\"Input: {i}, Output: {p_nor.output(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Initialiseer ook een Perceptron voor een uitgebreider beslissysteem (minimaal 3 inputs, zie bijvoorbeeld Figuur 2.8 uit de reader) en test of deze naar verwachting werkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'Min-2' with input weights [1, 1, 1] and bias -2.\n",
      "Input: (0, 0, 0), Output: 0\n",
      "Input: (0, 0, 1), Output: 0\n",
      "Input: (0, 1, 0), Output: 0\n",
      "Input: (0, 1, 1), Output: 1\n",
      "Input: (1, 0, 0), Output: 0\n",
      "Input: (1, 0, 1), Output: 1\n",
      "Input: (1, 1, 0), Output: 1\n",
      "Input: (1, 1, 1), Output: 1\n"
     ]
    }
   ],
   "source": [
    "p_two_min = Perceptron(\"Min-2\", [1, 1, 1], -2)\n",
    "print(p_two_min)\n",
    "\n",
    "for i in threebit_binary_combinations:\n",
    "    print(f\"Input: {i}, Output: {p_two_min.output(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De NAND is straks nodig voor het netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'NAND' with input weights [-1, -1] and bias 1.\n",
      "Input: (0, 0), Output: 1\n",
      "Input: (0, 1), Output: 1\n",
      "Input: (1, 0), Output: 1\n",
      "Input: (1, 1), Output: 0\n"
     ]
    }
   ],
   "source": [
    "p_nand = Perceptron(\"NAND\", [-1, -1], 1)\n",
    "print(p_nand)\n",
    "\n",
    "for i in twobit_binary_combinations:\n",
    "    print(f\"Input: {i}, Output: {p_nand.output(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Schrijf een klasse PerceptronLayer. Een laag heeft één of meer Perceptrons en levert bij activatie dus eenzelfde aantal outputs. Schrijf ook een __str__() methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronLayer():\n",
    "    def __init__(self, name, perceptrons):\n",
    "        self.name = name\n",
    "        self.perceptrons = perceptrons\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"PerceptronLayer '{self.name}' with {len(self.perceptrons)} perceptrons.\"\n",
    "\n",
    "    def output(self, input):\n",
    "        return [p.output(input) for p in self.perceptrons] if hasattr(self.perceptrons, '__iter__') else self.perceptrons.output(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Schrijf een klasse PerceptronNetwork. Een netwerk heeft één of meer PerceptronLayers. Schrijf een methode die de uitvoer van het netwerk bepaalt bij een gegeven input door middel van feed forward. Voeg ook een __str__() methode toe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronNetwork():\n",
    "    def __init__(self, name, layers):\n",
    "        self.name = name\n",
    "        self.layers = layers\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"PerceptronNetwork '{self.name}' with {len(self.layers)} layers.\"\n",
    "\n",
    "    def output(self, input):\n",
    "        for layer in self.layers:\n",
    "            # Feed forward\n",
    "            input = layer.output(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test je PerceptronNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Initialiseer een PerceptronNetwork voor de XOR-poort met twee ingangen en test of deze op de juiste manier werkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PerceptronNetwork 'XOR' with 2 layers.\n",
      "Input: (0, 0), Output: 0\n",
      "Input: (0, 1), Output: 1\n",
      "Input: (1, 0), Output: 1\n",
      "Input: (1, 1), Output: 0\n"
     ]
    }
   ],
   "source": [
    "xor_layer = PerceptronLayer(\"Logic\", [p_nand, p_or])\n",
    "xor_output_layer = PerceptronLayer(\"Output\", p_and)\n",
    "xor = PerceptronNetwork(\"XOR\", [xor_layer, xor_output_layer])\n",
    "print(xor)\n",
    "\n",
    "for i in twobit_binary_combinations:\n",
    "    print(f\"Input: {i}, Output: {xor.output(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Initialiseer een PerceptronNetwork voor de half adder en test of deze op de juiste manier werkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PerceptronNetwork 'Half Adder' with 2 layers.\n",
      "Input: (0, 0), Output: [0, 0]\n",
      "Input: (0, 1), Output: [0, 1]\n",
      "Input: (1, 0), Output: [0, 1]\n",
      "Input: (1, 1), Output: [1, 0]\n"
     ]
    }
   ],
   "source": [
    "half_adder_layer = PerceptronLayer(\"Half Adder\", [p_or, p_nand, p_and])\n",
    "\n",
    "p_HA_1 = Perceptron(\"Half Adder AND\", [0, 0, 1], bias=-1)\n",
    "p_HA_2 = Perceptron(\"Half Adder XOR\", [1, 1, 0], bias=-2)\n",
    "half_adder_output_layer = PerceptronLayer(\"Output\", [p_HA_1, p_HA_2])\n",
    "half_adder = PerceptronNetwork(\"Half Adder\", [half_adder_layer, half_adder_output_layer])\n",
    "print(half_adder)\n",
    "\n",
    "for i in twobit_binary_combinations:\n",
    "    print(f\"Input: {i}, Output: {half_adder.output(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(perceptron, train_data, learning_rate, method_value, method='loss'):\n",
    "    if method == 'loss':\n",
    "        while perceptron.loss() > method_value or perceptron.training_iterations < 1:\n",
    "            for input, desired in train_data:\n",
    "                perceptron.update(learning_rate, input, desired)\n",
    "    elif method == 'iterations':\n",
    "        while perceptron.training_iterations < method_value:\n",
    "            for input, desired in train_data:\n",
    "                perceptron.update(learning_rate, input, desired)\n",
    "    print(f\"Training complete after {perceptron.training_iterations} iterations with a final loss of {perceptron.loss()}.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'Train to AND' with input weights [4, 5] and bias -1.\n",
      "Training complete after 32 iterations with a final loss of 0.09375.\n",
      "Perceptron 'Train to AND' with input weights [3, 3] and bias -4.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "weights = [random.randint(-5, 5) for _ in range(2)]\n",
    "bias = random.randint(-5, 5)\n",
    "\n",
    "p_train = Perceptron(\"Train to AND\", weights, bias)\n",
    "print(p_train)\n",
    "\n",
    "AND_train = [\n",
    "    ((0, 0), 0),\n",
    "    ((0, 1), 0),\n",
    "    ((1, 0), 0),\n",
    "    ((1, 1), 1)\n",
    "]\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "loss_threshold = 0.1\n",
    "\n",
    "train_perceptron(p_train, AND_train, learning_rate, method='loss', method_value=loss_threshold)\n",
    "\n",
    "print(p_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'Train to AND' with input weights [3, 3] and bias -4.\n",
      "Input: (0, 0), Output: 0\n",
      "Input: (0, 1), Output: 0\n",
      "Input: (1, 0), Output: 0\n",
      "Input: (1, 1), Output: 1\n"
     ]
    }
   ],
   "source": [
    "p_and = p_train\n",
    "print(p_and)\n",
    "\n",
    "for i in twobit_binary_combinations:\n",
    "    print(f\"Input: {i}, Output: {p_and.output(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'Train to XOR' with input weights [1, -3] and bias 3.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m loss_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mtrain_perceptron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXOR_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(p_train)\n",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m, in \u001b[0;36mtrain_perceptron\u001b[1;34m(perceptron, train_data, learning_rate, method_value, method)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m perceptron\u001b[38;5;241m.\u001b[39mloss() \u001b[38;5;241m>\u001b[39m method_value \u001b[38;5;129;01mor\u001b[39;00m perceptron\u001b[38;5;241m.\u001b[39mtraining_iterations \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, desired \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[1;32m----> 5\u001b[0m             \u001b[43mperceptron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m perceptron\u001b[38;5;241m.\u001b[39mtraining_iterations \u001b[38;5;241m<\u001b[39m method_value:\n",
      "Cell \u001b[1;32mIn[47], line 26\u001b[0m, in \u001b[0;36mPerceptron.update\u001b[1;34m(self, learning_rate, input, desired)\u001b[0m\n\u001b[0;32m     24\u001b[0m error \u001b[38;5;241m=\u001b[39m desired \u001b[38;5;241m-\u001b[39m output\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m error\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m error \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m[i]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m error\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "weights = [random.randint(-5, 5) for _ in range(2)]\n",
    "bias = random.randint(-5, 5)\n",
    "\n",
    "p_train = Perceptron(\"Train to XOR\", weights, bias)\n",
    "print(p_train)\n",
    "\n",
    "XOR_train = [\n",
    "    ((0, 0), 0),\n",
    "    ((0, 1), 1),\n",
    "    ((1, 0), 1),\n",
    "    ((1, 1), 0)\n",
    "]\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "loss_threshold = 0.1\n",
    "\n",
    "train_perceptron(p_train, XOR_train, learning_rate, method='loss', method_value=loss_threshold)\n",
    "\n",
    "print(p_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 'Train to XOR' with input weights [2, 2] and bias -4.\n",
      "Input: (0, 0), Output: 0\n",
      "Input: (0, 1), Output: 0\n",
      "Input: (1, 0), Output: 0\n",
      "Input: (1, 1), Output: 1\n"
     ]
    }
   ],
   "source": [
    "p_xor = p_train\n",
    "print(p_xor)\n",
    "\n",
    "for i in twobit_binary_combinations:\n",
    "    print(f\"Input: {i}, Output: {p_xor.output(i)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
